{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Datos Inconsistentes\n",
        "\n",
        "En este JNB se revisarÃ¡ el tema de Datos Inconsistentes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O8NoTzxjs2wK",
        "outputId": "fa4bc249-a4fa-48a6-9dc6-7733646ed223"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hello World!\n"
          ]
        }
      ],
      "source": [
        "In this notebook, we're going to learn how to clean up inconsistent text entries.\n",
        "\n",
        "Let's get started!\n",
        "\n",
        "Get our environment set up\n",
        "The first thing we'll need to do is load in the libraries and dataset we'll be using.\n",
        "\n",
        "# modules we'll use\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# helpful modules\n",
        "import fuzzywuzzy\n",
        "from fuzzywuzzy import process\n",
        "import charset_normalizer\n",
        "\n",
        "# read in all our data\n",
        "professors = pd.read_csv(\"../input/pakistan-intellectual-capital/pakistan_intellectual_capital.csv\")\n",
        "\n",
        "# set seed for reproducibility\n",
        "np.random.seed(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "professors.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# get all the unique values in the 'Country' column\n",
        "countries = professors['Country'].unique()\n",
        "\n",
        "# sort them alphabetically and then take a closer look\n",
        "countries.sort()\n",
        "countries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# convert to lower case\n",
        "professors['Country'] = professors['Country'].str.lower()\n",
        "# remove trailing white spaces\n",
        "professors['Country'] = professors['Country'].str.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# get all the unique values in the 'Country' column\n",
        "countries = professors['Country'].unique()\n",
        "\n",
        "# sort them alphabetically and then take a closer look\n",
        "countries.sort()\n",
        "countries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# get the top 10 closest matches to \"south korea\"\n",
        "matches = fuzzywuzzy.process.extract(\"south korea\", countries, limit=10, scorer=fuzzywuzzy.fuzz.token_sort_ratio)\n",
        "\n",
        "# take a look at them\n",
        "matches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# function to replace rows in the provided column of the provided dataframe\n",
        "# that match the provided string above the provided ratio with the provided string\n",
        "def replace_matches_in_column(df, column, string_to_match, min_ratio = 47):\n",
        "    # get a list of unique strings\n",
        "    strings = df[column].unique()\n",
        "    \n",
        "    # get the top 10 closest matches to our input string\n",
        "    matches = fuzzywuzzy.process.extract(string_to_match, strings, \n",
        "                                         limit=10, scorer=fuzzywuzzy.fuzz.token_sort_ratio)\n",
        "\n",
        "    # only get matches with a ratio > 90\n",
        "    close_matches = [matches[0] for matches in matches if matches[1] >= min_ratio]\n",
        "\n",
        "    # get the rows of all the close matches in our dataframe\n",
        "    rows_with_matches = df[column].isin(close_matches)\n",
        "\n",
        "    # replace all rows with close matches with the input matches \n",
        "    df.loc[rows_with_matches, column] = string_to_match\n",
        "    \n",
        "    # let us know the function's done\n",
        "    print(\"All done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# use the function we just wrote to replace close matches to \"south korea\" with \"south korea\"\n",
        "replace_matches_in_column(df=professors, column='Country', string_to_match=\"south korea\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# get all the unique values in the 'Country' column\n",
        "countries = professors['Country'].unique()\n",
        "\n",
        "# sort them alphabetically and then take a closer look\n",
        "countries.sort()\n",
        "countries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "EJERCICIOS KAGGLE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# modules we'll use\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# helpful modules\n",
        "import fuzzywuzzy\n",
        "from fuzzywuzzy import process\n",
        "import charset_normalizer\n",
        "\n",
        "# read in all our data\n",
        "professors = pd.read_csv(\"../input/pakistan-intellectual-capital/pakistan_intellectual_capital.csv\")\n",
        "\n",
        "# set seed for reproducibility\n",
        "np.random.seed(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# convert to lower case\n",
        "professors['Country'] = professors['Country'].str.lower()\n",
        "# remove trailing white spaces\n",
        "professors['Country'] = professors['Country'].str.strip()\n",
        "\n",
        "# get the top 10 closest matches to \"south korea\"\n",
        "countries = professors['Country'].unique()\n",
        "matches = fuzzywuzzy.process.extract(\"south korea\", countries, limit=10, scorer=fuzzywuzzy.fuzz.token_sort_ratio)\n",
        "\n",
        "def replace_matches_in_column(df, column, string_to_match, min_ratio = 47):\n",
        "    # get a list of unique strings\n",
        "    strings = df[column].unique()\n",
        "    \n",
        "    # get the top 10 closest matches to our input string\n",
        "    matches = fuzzywuzzy.process.extract(string_to_match, strings, \n",
        "                                         limit=10, scorer=fuzzywuzzy.fuzz.token_sort_ratio)\n",
        "\n",
        "    # only get matches with a ratio > 90\n",
        "    close_matches = [matches[0] for matches in matches if matches[1] >= min_ratio]\n",
        "\n",
        "    # get the rows of all the close matches in our dataframe\n",
        "    rows_with_matches = df[column].isin(close_matches)\n",
        "\n",
        "    # replace all rows with close matches with the input matches \n",
        "    df.loc[rows_with_matches, column] = string_to_match\n",
        "    \n",
        "    # let us know the function's done\n",
        "    print(\"All done!\")\n",
        "    \n",
        "replace_matches_in_column(df=professors, column='Country', string_to_match=\"south korea\")\n",
        "countries = professors['Country'].unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1) Examine another column\n",
        "Write code below to take a look at all the unique values in the \"Graduated from\" column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "unis = professors['Graduated from'].unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2) Do some text pre-processing\n",
        "Convert every entry in the \"Graduated from\" column in the professors DataFrame to remove white spaces at the beginning and end of cells."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "professors['Graduated from'] = professors['Graduated from'].str.strip()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3) Continue working with countries\n",
        "In the tutorial, we focused on cleaning up inconsistencies in the \"Country\" column. Run the code cell below to view the list of unique values that we ended with."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "countries = professors['Country'].unique()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Take another look at the \"Country\" column and see if there's any more data cleaning we need to do.\n",
        "\n",
        "It looks like 'usa' and 'usofa' should be the same country. Correct the \"Country\" column in the dataframe to replace 'usofa' with 'usa'.\n",
        "\n",
        "Use the most recent version of the DataFrame (with the whitespaces at the beginning and end of cells removed) from question 2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "matches = fuzzywuzzy.process.extract(\"usa\", countries, limit=10, scorer=fuzzywuzzy.fuzz.token_sort_ratio)\n",
        "replace_matches_in_column(df=professors, column='Country', string_to_match=\"usa\", min_ratio=70)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.7 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "eb4a0ac80907d7f44e1a5e88d3d3381b33e3dbedd3a24d113e876f30a0c46bee"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
