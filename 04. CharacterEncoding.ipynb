{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Codificación de Caracteres\n",
        "\n",
        "En este JNB se revisará el tema de Codificación de Caracteres."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O8NoTzxjs2wK",
        "outputId": "fa4bc249-a4fa-48a6-9dc6-7733646ed223"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hello World!\n"
          ]
        }
      ],
      "source": [
        "# modules we'll use\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# helpful character encoding module\n",
        "import charset_normalizer\n",
        "\n",
        "# set seed for reproducibility\n",
        "np.random.seed(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# start with a string\n",
        "before = \"This is the euro symbol: €\"\n",
        "\n",
        "# check to see what datatype it is\n",
        "type(before)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# encode it to a different encoding, replacing characters that raise errors\n",
        "after = before.encode(\"utf-8\", errors=\"replace\")\n",
        "\n",
        "# check the type\n",
        "type(after)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# take a look at what the bytes look like\n",
        "after"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# convert it back to utf-8\n",
        "print(after.decode(\"utf-8\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# try to decode our bytes with the ascii encoding\n",
        "print(after.decode(\"ascii\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# start with a string\n",
        "before = \"This is the euro symbol: €\"\n",
        "\n",
        "# encode it to a different encoding, replacing characters that raise errors\n",
        "after = before.encode(\"ascii\", errors = \"replace\")\n",
        "\n",
        "# convert it back to utf-8\n",
        "print(after.decode(\"ascii\"))\n",
        "\n",
        "# We've lost the original underlying byte string! It's been \n",
        "# replaced with the underlying byte string for the unknown character :("
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# try to read in a file not in UTF-8\n",
        "kickstarter_2016 = pd.read_csv(\"../input/kickstarter-projects/ks-projects-201612.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# look at the first ten thousand bytes to guess the character encoding\n",
        "with open(\"../input/kickstarter-projects/ks-projects-201801.csv\", 'rb') as rawdata:\n",
        "    result = charset_normalizer.detect(rawdata.read(10000))\n",
        "\n",
        "# check what the character encoding might be\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# read in the file with the encoding detected by charset_normalizer\n",
        "kickstarter_2016 = pd.read_csv(\"../input/kickstarter-projects/ks-projects-201612.csv\", encoding='Windows-1252')\n",
        "\n",
        "# look at the first few lines\n",
        "kickstarter_2016.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# save our file (will be saved as UTF-8 by default!)\n",
        "kickstarter_2016.to_csv(\"ks-projects-201801-utf8.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "EJERCICIOS KAGGLE\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# modules we'll use\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# helpful character encoding module\n",
        "import charset_normalizer\n",
        "\n",
        "# set seed for reproducibility\n",
        "np.random.seed(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1) What are encodings?\n",
        "You're working with a dataset composed of bytes. Run the code cell below to print a sample entry."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sample_entry = b'\\xa7A\\xa6n'\n",
        "print(sample_entry)\n",
        "print('data type:', type(sample_entry))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Use the next code cell to create a variable new_entry that changes the encoding from \"big5-tw\" to \"utf-8\". new_entry should have the bytes datatype."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "before = sample_entry.decode(\"big5-tw\")\n",
        "new_entry = before.encode()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2) Reading in files with encoding problems\n",
        "Use the code cell below to read in this file at path \"../input/fatal-police-shootings-in-the-us/PoliceKillingsUS.csv\".\n",
        "\n",
        "Figure out what the correct encoding should be and read in the file to a DataFrame police_killings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "police_killings = pd.read_csv(\"../input/fatal-police-shootings-in-the-us/PoliceKillingsUS.csv\", encoding='Windows-1252')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3) Saving your files with UTF-8 encoding\n",
        "Save a version of the police killings dataset to CSV with UTF-8 encoding. Your answer will be marked correct after saving this file.\n",
        "\n",
        "Note: When using the to_csv() method, supply only the name of the file (e.g., \"my_file.csv\"). This saves the file at the filepath \"/kaggle/working/my_file.csv\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "police_killings.to_csv(\"my_file.csv\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.7 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "eb4a0ac80907d7f44e1a5e88d3d3381b33e3dbedd3a24d113e876f30a0c46bee"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
